---
title: "svm"
author: "Carolina Cornejo Castellano"
date: '`r Sys.Date()`'
output: pdf_document
---

# Libraries

```{r message=FALSE, warning=FALSE, include=FALSE}
library(tidyverse)
library(caret) # for machine learning
library(naniar) # for better handling NA
library(fastDummies) # for 'dummifying' categorical variables
library(factoextra)
library(ROCR) #for plotting AUC
library(janitor) # for standardizing column names
library(MASS)
library(e1071)
library(pROC)
library(kernlab) # ksvm
library(doParallel) # for parallel programming
```

# Sourcing 2017 data and cleaning

```{r this is the training data}
source("cleaning_2017.R")
```

# Sourcing 2018 data and cleaning

```{r this is test data}
source("cleaning_2018.R")
```

# Sourcing 2016 data and cleaning

Following the recommendations of one of our lecturers, we tested the ksvm model of the `kernlab` package with other data, because the predictions on 2018 data were too good. So, we chose 2016 data.

```{r sourcing 2016 data to take it as a second test data}
source("cleaning_2016.R")
```


# SVM model

```{r create train and test datasets, fit the model and test}
# create a training set and a test set for predicting unem based on the 2017 data

set.seed(666)

trainIndex <- createDataPartition(df_dummified_2017$unem, 
                                  p = 0.8, 
                                  list = FALSE)
train <- df_dummified_2017[trainIndex, ]
test <- df_dummified_2017[-trainIndex, ]

# fit the model
svm_model <- ksvm(unem ~ .,
    data = train,
    kernel = "rbfdot",
    C = 1,
    scale = FALSE
)

# testing the model
test_pred_2017 <- predict(svm_model, test)
```

```{r roc}
set.seed(234)
"ROC curve and AUC"

roc_2017 = roc(response = test$unem, 
               predictor = as.numeric(test_pred_2017))
roc_2017

control = 0
case = 1

plot.roc(roc_2017, 
         col = "red", 
         lwd = 3, 
         main = "ROC curve fdi")
```
The latter means that R is assuming that the "control" level of the variable is the negative class and the "case" level is the positive class.

```{r confusion matrix based on 2017 test set predictions}
con_matrix_2017 <- confusionMatrix(test$unem, test_pred_2017)
con_matrix_2017
```

## Predicting unemployment in 2018 with SVM fit based on 2017 data

```{r}

```


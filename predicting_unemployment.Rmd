---
title: "svm"
author: "Carolina Cornejo Castellano"
date: '`r Sys.Date()`'
output: pdf_document
---

# Libraries

```{r message=FALSE, warning=FALSE, include=FALSE}
library(tidyverse)
library(caret) # for machine learning
library(naniar) # for better handling NA
library(fastDummies) # for 'dummifying' categorical variables
library(factoextra)
library(ROCR) #for plotting AUC
library(janitor) # for standardizing column names
library(MASS)
library(e1071)
library(pROC)
library(kernlab) # ksvm
library(doParallel) # for parallel programming
```

# Sourcing 2017 data and cleaning

```{r this is the training data}
source("cleaning_2017.R")
```

# Sourcing 2018 data and cleaning

```{r this is test data}
source("cleaning_2018.R")
```

# Sourcing 2016 data and cleaning

Following the recommendations of one of our lecturers, we tested the ksvm model of the `kernlab` package with other data, because the predictions on 2018 data were too good. So, we chose 2016 data.

```{r sourcing 2016 data to take it as a second test data}
source("cleaning_2016.R")
```

# SVM model

```{r create train and test datasets, fit the model and test}
# create a training set and a test set for predicting unem based on the 2017 data

set.seed(666)
trainIndex <- createDataPartition(df_dummified_2017$unem, p = 0.8, list = FALSE)
train <- df_dummified_2017[trainIndex, ]
test <- df_dummified_2017[-trainIndex, ]

# fit the model
svm_model <- ksvm(unem ~ .,
    data = train,
    kernel = "rbfdot",
    C = 1,
    scale = FALSE
)

# testing the model
test_pred <- predict(svm_model, test)

# ploting the AUC
auc <- roc(test$unem, test_pred)
```

```{r}
# confussion matrix
confusion <- confusionMatrix(test$unem, test_pred)
confusion
```
